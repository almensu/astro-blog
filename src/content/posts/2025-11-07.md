---
title: 我甚至没打开文件夹：10分钟把 406 个散乱文档洗成 1 个完美知识库，竟然花了我xx元
date: 2025-11-07
summary: 10分钟花2块3毛1，AI帮我搞定406个文档合并！国产大模型接入Claude Code实战：从搭建到生产力革命，揭秘如何用半瓶可乐钱买回半天时间，体验真正的AI编程助手威力。
category: AI工具评测
tags: [AI编程, 大模型应用, 生产力工具, Claude Code, 国产大模型, 自动化脚本, 成本分析]
---

这阵子，国产大模型圈子简直“杀疯了”，豆包、Kimi、DeepSeek... 新模型一个接一个，是不是都看花眼了？

很多人（包括我）最顺手的还是 Claude Code 这个终端，界面清爽、功能强大。可惜，人家对我们“不开放”。

但作为技术流玩家，我们的信条是：工具是死的，人是活的。

今天就跟大伙儿聊聊，我怎么“曲线救国”，把一众国产大模型丝滑接入 Claude Code，并且用“真金白银”实战了一把，给你们探探路。

## Part 1: 我的“军火库”搭建思路（保姆级教程）

> P.S. 本人是 macOS 用户，所以以下教程均以 macOS (zsh) 环境为例，Linux 用户命令 basic 一致，请自行微调。

最近看了阮一峰老师那篇《国产大模型接入 Claude Code 教程》，大受启发。他用豆包（Doubao-Seed-Code）做了演示。

核心思路是**“偷天换日”**：不碰你原来的全局 claude 命令，而是新建一个项目目录，在里面“本地安装”一个 Claude Code，然后通过“马甲”脚本来切换底层模型。

### 第一步：创建项目目录并安装 Claude Code

打开你的终端，跟着我一步步敲：

```bash
# 1. 在你的用户主目录下，创建一个专门放这些模型的目录
mkdir ~/claude-model

# 2. 进入这个目录
cd ~/claude-model

# 3. 初始化一个 node.js 项目（一路回车）
npm init -y

# 4. 在这个目录“本地安装” Claude Code
# (这是关键，我们不动全局安装的那个)
npm install @anthropic-ai/claude-code

# 5. 创建一个存放“马甲”脚本的 bin 目录
mkdir bin
```

### 第二步：创建豆包“马甲”脚本

```bash
# 1. 在 bin 目录里，新建一个叫 claude-doubao 的文件
touch bin/claude-doubao

# 2. 赋予这个文件“可执行”权限
chmod +x bin/claude-doubao
```

现在，用你顺手的编辑器（比如 VS Code，执行 `code bin/claude-doubao`）打开这个刚创建的 `claude-doubao` 文件，把下面的脚本内容完整复制进去：

```bash
#!/usr/bin/env bash
# Wrapper for Claude Code CLI using Doubao API

# 找到我们本地安装的 claude 可执行文件
CLAUDE_BIN="$HOME/claude-model/node_modules/.bin/claude"

# 注入豆包的凭证
export ANTHROPIC_AUTH_TOKEN="你的_DOUBAO_API_KEY"
export ANTHROPIC_BASE_URL="https://ark.cn-beijing.volces.com/api/compatible"
export ANTHROPIC_MODEL="doubao-seed-code-preview-latest"

# (可选)保持配置独立，防止和全局claude冲突
export CLAUDE_CONFIG_DIR="$HOME/claude-model/.claude-doubao"

# 执行真正的 claude 命令，并把所有参数传给它
exec "$CLAUDE_BIN" "$@"
```

### 第三步：配置环境变量，让系统“认识”你的马甲

打开你的 `~/.zshrc` 文件 (如果你用的是 bash，那就是 `~/.bash_profile`)，在文件末尾加一行：

```bash
# 告诉系统，去 ~/claude-model/bin 目录也找找命令
export PATH="$HOME/claude-model/bin:$PATH"
```

保存退出。然后重启你的终端，或者执行 `source ~/.zshrc` 来让配置立即生效。

OK！现在你就可以用 `claude-doubao` 命令来启动 Claude Code 了，它用的就是豆包模型。

**举一反三**：你可以用同样的方法，复制 `claude-doubao` 为 `claude-kimi`，然后把里面的 API Key 和 Base URL 换成 Kimi 的配置，实现“模型自由”。

## Part 2: 尝试“聚合平台”——硅基流动

后来我又发现一个叫“硅基流动”（Silicon Flow）的平台，它像个“模型超市”，把 DeepSeek、Kimi、MiniMax 全聚合了，给一个统一的 API 入口。

他们提供了两种接入 Claude Code 的方案，我研究了一下：

### 方式一：一键安装及配置脚本 (官方推荐)

这是最简单的方法。在终端中运行以下命令：

```bash
bash -c "$(curl -fsSL https://static01.siliconflow.cn/cdn/assets/ccsf_v2_3.sh)"
```

- 脚本会提示你输入 API Key，这时粘贴你的 SiliconFlow API Key。
- 接着会提示选择模型，用方向键选择一个，或者选“自定义”然后去他们模型广场复制模型名称。
- 完成后，根据提示复制相应命令并重启终端，应用配置。

执行 `claude` 命令，进入 Claude Code 后，你就可以用 `/model` 命令来切换你选中的定制化模型了。

> 注意：官方提到 Claude Code 目前并不支持添加多个自定义模型。您可以再次执行上述脚本，选择并更新 ANTHROPIC_MODEL 环境变量的方式来切换模型。

### 方式二：手动配置 Claude Code 环境变量

如果你不想用脚本，也可以手动在你的 `~/.zshrc` (或 `~/.bash_profile`) 文件里添加环境变量。

这是我个人的配置案例，我喜欢用 `#` 注释来快速切换模型：

```bash
export ANTHROPIC_BASE_URL="https://api.siliconflow.cn"

export ANTHROPIC_API_KEY="YOUR_SiliconFlow_API_KEY"

export ANTHROPIC_MODEL=deepseek-ai/DeepSeek-V3.1-Terminus
#export ANTHROPIC_MODEL=MiniMaxAI/MiniMax-M2
#export ANTHROPIC_MODEL=Pro/deepseek-ai/DeepSeek-V3.1-Terminus
#export ANTHROPIC_MODEL=moonshotai/Kimi-K2-Thinking
```

### 方案总结：马甲 vs 聚合

好了，两种方案都介绍完了。我帮大家总结一下：

- **“马甲”脚本方案 (Part 1)**：非常适合那些有独家 API 的模型，比如豆包（火山引擎）系列。每个模型一个脚本，物理隔离，互不干扰。
- **“硅基流动”方案 (Part 2)**：这是一个聚合平台，它把DeepSeek、Kimi (月之暗面)、MiniMax等多个厂商的模型打包，用一个 API Key 就能调用所有，适合想“图省事”和“货比三家”的朋友。

到底用哪个？看表格：

| 对比维度     | “马甲”脚本方案 (Part 1)                               | 硅基流动方案 (Part 2)                                           |
| ------------ | ----------------------------------------------------- | --------------------------------------------------------------- |
| 最佳适用     | 独家模型 (如 豆包系列)                                | 聚合模型 (DeepSeek, Kimi 等)                                    |
| 模型切换     | 极简：不同命令 (claude-doubao, claude-kimi)，互不干扰 | 稍繁琐：需重新运行脚本，或手动修改 .zshrc 文件（注释/取消注释） |
| 配置复杂度   | 稍高：需为每个模型创建bin脚本文件                     | 较低：一个脚本或几行环境变量搞定                                |
| API Key 管理 | 需管理多个API Key（豆包一个，Kimi一个...）            | 极简：一个 硅基流动 Key 搞定所有模型                            |
| 我的偏好     | "多模型洁癖"首选，隔离性好                            | "图省事"首选，一个入口调用万物                                  |

## Part 3: 真金白银实战：合并406个Flomo笔记

光说不练假把式。我这儿有个刚需：我导出了 406 个 flomo 格式的 .md 文件，散落在一个 FormFlomo 文件夹里。

我这么做的目的，是想把我所有感兴趣的零散记录做一个分类汇总，方便 AI（比如我正在用的 Gemini ）能更懂我，推测出我的个人感受和经历。

### 核心需求

把这 406 个文件的内容，合并到 一个 `合并.md` 文件里。并且，每个文件的内容，要用它的文件名（去掉.md）作为标签包起来，像这样：

```
<文件名1>
文件1的内容...
</文件名1>

<文件名2-2>
文件2-2的内容...
</文件名2-2>
```

朋友们，这活儿要是手动干…… 一个上午没了，还得是眼不花、手不抖的情况下。

于是我打开终端，敲下 `claude`（如果你用的官方方案），直接把需求扔给了它。（我用的是硅基流动的 DeepSeek 模型）

接下来的10分钟，我见证了奇迹。

它没有傻乎乎地去读文件，而是：

1. 先Search了一下，确认有 FormFlomo 目录。
2. 再 `find ... | wc -l`，确认了有 406 个 .md 文件。
3. 然后，它给我写了个 `merge_md_files.py` —— 一个完整的 Python 脚本，带参数解析、错误处理、甚至还有进度条！
4. 接着，它又写了个 `merge.sh` —— 一个更易用的 Shell 启动脚本，还带漂亮的彩色输出！
5. 最后，它还“贴心”地写了个 `README.md`，告诉我怎么用这套工具。

它自己测试、自己创建、自己跑通。10分钟后，`合并.md` 文件静静地躺在了我的目录里，6179 行，格式完美。

我，非常满意。 这10分钟，它干的不是“合并”，而是“开发了一套合并工具”。

## Part 4: 灵魂拷问：10分钟，2块3毛1，贵吗？

任务完成，我马上去后台看了眼账单：

| 产品名称                           | 用量           | 消费总额（元） |
| ---------------------------------- | -------------- | -------------- |
| deepseek-ai/DeepSeek-V3.1-Terminus | 567,382 Tokens | 2.3118         |

是的，10分钟，花了2块3毛1。

说实话，第一反应是：“嚯，国产模型不便宜啊！”（当然，这价格相比 Claude 官方模型，已经便宜太多了。）

但转念一想：

- 这2块3毛钱，买了我半天（可能还搞不定）的重复劳动时间。
- 它不是简单的CV（复制粘贴），它理解了我的需求，并给出了一个“工程化”的解决方案（Python脚本+Shell脚本+ReadMe）。

从这个角度看，这2块钱，简直是“白菜价”。我用买半瓶可乐的钱，雇了一个10分钟的资深程序员。

我唯一的希望是：再过一年，这个成本能降到2毛钱。

到那时，AI 才真正从一个“偶尔用用很惊艳”的工具，变成了我们“离不开”的生产力（或者说，大脑外挂）。

你怎么看？为了节省半天时间，你愿意花这2块钱吗？

评论区聊聊。
